import streamlit as st
import json
import base64
import io
from datetime import datetime
from utils.common import create_tool_header, show_progress_bar, add_to_recent
from utils.file_handler import FileHandler
from utils.ai_client import ai_client

def display_tools():
    """Display all AI tools"""
    
    tool_categories = {
        "Multiple AI Model Integrations": [
            "Model Comparison", "Multi-Model Chat", "Model Selector", "Performance Benchmark", "API Manager"
        ],
        "Text Generation": [
            "Content Creator", "Story Writer", "Article Generator", "Copywriting Assistant", "Technical Writer"
        ],
        "Image Generation": [
            "AI Art Creator", "Style Transfer", "Image Synthesis", "Concept Art", "Photo Enhancement"
        ],
        "Data Analysis": [
            "Pattern Recognition", "Trend Analysis", "Predictive Modeling", "Data Insights", "Statistical Analysis"
        ],
        "Chatbots": [
            "Conversational AI", "Customer Service Bot", "Educational Assistant", "Domain Expert", "Multi-Purpose Bot"
        ],
        "Language Processing": [
            "Text Translator", "Sentiment Analysis", "Text Summarizer", "Language Detector", "Content Moderator"
        ],
        "Computer Vision": [
            "Image Recognition", "Object Detection", "Scene Analysis", "OCR Reader", "Visual Search"
        ],
        "AI Utilities": [
            "Model Comparison", "Prompt Optimizer", "AI Workflow", "Batch Processor", "Response Analyzer"
        ],
        "Machine Learning": [
            "Model Training", "Data Preprocessing", "Feature Engineering", "Model Evaluation", "AutoML"
        ],
        "Voice & Audio": [
            "Speech Recognition", "Voice Synthesis", "Audio Analysis", "Voice Cloning", "Sound Generation"
        ]
    }
    
    selected_category = st.selectbox("Select AI Tool Category", list(tool_categories.keys()))
    selected_tool = st.selectbox("Select Tool", tool_categories[selected_category])
    
    st.markdown("---")
    
    add_to_recent(f"AI Tools - {selected_tool}")
    
    # Display selected tool
    if selected_tool == "Multi-Model Chat":
        multi_model_chat()
    elif selected_tool == "Content Creator":
        content_creator()
    elif selected_tool == "AI Art Creator":
        ai_art_creator()
    elif selected_tool == "Sentiment Analysis":
        sentiment_analysis()
    elif selected_tool == "Image Recognition":
        image_recognition()
    elif selected_tool == "Text Translator":
        text_translator()
    elif selected_tool == "Text Summarizer":
        text_summarizer()
    elif selected_tool == "Model Comparison":
        model_comparison()
    elif selected_tool == "Prompt Optimizer":
        prompt_optimizer()
    elif selected_tool == "Data Insights":
        data_insights()
    elif selected_tool == "Conversational AI":
        conversational_ai()
    elif selected_tool == "OCR Reader":
        ocr_reader()
    elif selected_tool == "Voice Synthesis":
        voice_synthesis()
    elif selected_tool == "Pattern Recognition":
        pattern_recognition()
    elif selected_tool == "Story Writer":
        story_writer()
    else:
        st.info(f"{selected_tool} tool is being implemented. Please check back soon!")

def multi_model_chat():
    """Chat with multiple AI models simultaneously"""
    create_tool_header("Multi-Model Chat", "Chat with multiple AI models at once", "ü§ñ")
    
    # Model selection
    st.subheader("Select AI Models")
    available_models = ai_client.get_available_models()
    
    if not available_models:
        st.warning("No AI models available. Please check your API keys.")
        return
    
    selected_models = st.multiselect("Choose Models", available_models, default=available_models[:2] if len(available_models) >= 2 else available_models)
    
    if not selected_models:
        st.warning("Please select at least one model.")
        return
    
    # Chat interface
    st.subheader("Multi-Model Conversation")
    
    # Initialize chat history
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # User input
    user_message = st.text_area("Enter your message:", height=100)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("Send to All Models"):
            if user_message:
                send_to_all_models(user_message, selected_models)
    
    with col2:
        if st.button("Clear History"):
            st.session_state.chat_history = []
            st.rerun()
    
    with col3:
        if st.button("Export Chat"):
            export_chat_history()
    
    # Display chat history
    if st.session_state.chat_history:
        st.subheader("Conversation History")
        
        for entry in st.session_state.chat_history:
            # User message
            st.markdown(f"**üë§ You:** {entry['user_message']}")
            
            # Model responses
            for model, response in entry['responses'].items():
                with st.expander(f"ü§ñ {model.title()} Response"):
                    st.write(response)
            
            st.markdown("---")

def content_creator():
    """AI-powered content creation tool"""
    create_tool_header("Content Creator", "Generate various types of content with AI", "‚úçÔ∏è")
    
    content_type = st.selectbox("Content Type", [
        "Blog Post", "Social Media Post", "Email", "Product Description", 
        "Press Release", "Technical Documentation", "Creative Writing", "Marketing Copy"
    ])
    
    # Content parameters
    st.subheader("Content Parameters")
    
    col1, col2 = st.columns(2)
    with col1:
        topic = st.text_input("Topic/Subject", placeholder="Enter the main topic")
        target_audience = st.selectbox("Target Audience", [
            "General Public", "Professionals", "Students", "Experts", "Children", "Teenagers"
        ])
        tone = st.selectbox("Tone", [
            "Professional", "Casual", "Friendly", "Formal", "Humorous", "Persuasive", "Educational"
        ])
    
    with col2:
        length = st.selectbox("Content Length", [
            "Short (100-300 words)", "Medium (300-800 words)", "Long (800-1500 words)", "Very Long (1500+ words)"
        ])
        language = st.selectbox("Language", [
            "English", "Spanish", "French", "German", "Italian", "Portuguese", "Chinese", "Japanese"
        ])
        creativity = st.slider("Creativity Level", 0.1, 1.0, 0.7, 0.1)
    
    # Additional options
    if content_type in ["Blog Post", "Technical Documentation"]:
        include_outline = st.checkbox("Include Outline/Structure")
        include_seo = st.checkbox("SEO Optimized")
    
    if content_type == "Social Media Post":
        platform = st.selectbox("Platform", ["Twitter", "Facebook", "LinkedIn", "Instagram", "TikTok"])
        include_hashtags = st.checkbox("Include Hashtags")
    
    additional_instructions = st.text_area("Additional Instructions (optional)", 
                                         placeholder="Any specific requirements or guidelines...")
    
    if st.button("Generate Content") and topic:
        with st.spinner("Generating content with AI..."):
            # Build kwargs dict with only the extra parameters we need
            extra_kwargs = {}
            if content_type in ["Blog Post", "Technical Documentation"]:
                extra_kwargs['include_outline'] = locals().get('include_outline', False)
                extra_kwargs['include_seo'] = locals().get('include_seo', False)
            if content_type == "Social Media Post":
                extra_kwargs['platform'] = locals().get('platform', 'general')
                extra_kwargs['include_hashtags'] = locals().get('include_hashtags', False)
            
            content = generate_content(
                content_type, topic, target_audience, tone, length, 
                language, creativity, additional_instructions,
                **extra_kwargs
            )
            
            if content:
                st.subheader("Generated Content")
                st.markdown(content)
                
                # Content analysis
                st.subheader("Content Analysis")
                analysis = analyze_content(content)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Word Count", analysis['word_count'])
                with col2:
                    st.metric("Reading Time", f"{analysis['reading_time']} min")
                with col3:
                    st.metric("Readability", analysis['readability_level'])
                
                # Download options
                FileHandler.create_download_link(
                    content.encode(), 
                    f"{content_type.lower().replace(' ', '_')}.txt", 
                    "text/plain"
                )
                
                # Regenerate options
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("Regenerate"):
                        st.rerun()
                with col2:
                    if st.button("Refine Content"):
                        refine_content(content)

def ai_art_creator():
    """AI-powered image generation"""
    create_tool_header("AI Art Creator", "Generate images using AI", "üé®")
    
    # Image generation parameters
    st.subheader("Image Generation Settings")
    
    col1, col2 = st.columns(2)
    with col1:
        prompt = st.text_area("Image Description", 
                             placeholder="Describe the image you want to create...", 
                             height=100)
        style = st.selectbox("Art Style", [
            "Realistic", "Digital Art", "Oil Painting", "Watercolor", "Sketch", 
            "Anime/Manga", "Comic Book", "Abstract", "Surreal", "Minimalist"
        ])
        mood = st.selectbox("Mood/Atmosphere", [
            "Neutral", "Happy", "Dramatic", "Peaceful", "Mysterious", "Energetic", "Melancholic"
        ])
    
    with col2:
        resolution = st.selectbox("Resolution", ["1024x1024", "1024x768", "768x1024", "512x512"])
        color_scheme = st.selectbox("Color Scheme", [
            "Natural", "Vibrant", "Monochrome", "Warm Tones", "Cool Tones", "Pastel", "High Contrast"
        ])
        quality = st.selectbox("Quality", ["Standard", "High", "Ultra"])
    
    # Advanced options
    with st.expander("Advanced Options"):
        negative_prompt = st.text_area("Negative Prompt (what to avoid)", 
                                     placeholder="low quality, blurry, distorted...")
        seed = st.number_input("Seed (for reproducibility)", min_value=0, value=0)
        num_images = st.slider("Number of Images", 1, 4, 1)
    
    if st.button("Generate Image") and prompt:
        with st.spinner("Creating AI artwork..."):
            # Enhanced prompt
            enhanced_prompt = enhance_image_prompt(prompt, style, mood, color_scheme)
            
            st.info(f"Enhanced prompt: {enhanced_prompt}")
            
            # Generate image
            image_data = ai_client.generate_image(enhanced_prompt)
            
            if image_data:
                st.subheader("Generated Artwork")
                
                # Display image
                st.image(io.BytesIO(image_data), caption="AI Generated Image")
                
                # Image details
                st.subheader("Generation Details")
                generation_info = {
                    "Original Prompt": prompt,
                    "Enhanced Prompt": enhanced_prompt,
                    "Style": style,
                    "Mood": mood,
                    "Color Scheme": color_scheme,
                    "Resolution": resolution,
                    "Generated At": datetime.now().isoformat()
                }
                
                for key, value in generation_info.items():
                    st.write(f"**{key}**: {value}")
                
                # Download options
                FileHandler.create_download_link(
                    image_data, 
                    f"ai_artwork_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png", 
                    "image/png"
                )
                
                # Save generation info
                info_json = json.dumps(generation_info, indent=2)
                FileHandler.create_download_link(
                    info_json.encode(), 
                    f"generation_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 
                    "application/json"
                )
            else:
                st.error("Failed to generate image. Please try again with a different prompt.")

def sentiment_analysis():
    """Analyze sentiment of text"""
    create_tool_header("Sentiment Analysis", "Analyze text sentiment using AI", "üòä")
    
    # Input options
    input_method = st.radio("Input Method", ["Text Input", "File Upload"])
    
    if input_method == "Text Input":
        text = st.text_area("Enter text to analyze:", height=200)
    else:
        uploaded_file = FileHandler.upload_files(['txt', 'csv'], accept_multiple=False)
        if uploaded_file:
            text = FileHandler.process_text_file(uploaded_file[0])
            st.text_area("Uploaded text:", text, height=150, disabled=True)
        else:
            text = ""
    
    # Analysis options
    st.subheader("Analysis Options")
    
    col1, col2 = st.columns(2)
    with col1:
        analysis_depth = st.selectbox("Analysis Depth", ["Basic", "Detailed", "Comprehensive"])
        include_emotions = st.checkbox("Include Emotion Detection", True)
    
    with col2:
        batch_analysis = st.checkbox("Batch Analysis (by sentences)")
        confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.5, 0.1)
    
    if st.button("Analyze Sentiment") and text:
        with st.spinner("Analyzing sentiment..."):
            # Perform sentiment analysis
            analysis_result = ai_client.analyze_sentiment(text)
            
            if 'error' not in analysis_result:
                st.subheader("Sentiment Analysis Results")
                
                # Overall sentiment
                col1, col2, col3 = st.columns(3)
                with col1:
                    sentiment = analysis_result.get('sentiment', 'Unknown')
                    color = get_sentiment_color(sentiment)
                    st.markdown(f"**Overall Sentiment**: <span style='color: {color}'>{sentiment.title()}</span>", 
                               unsafe_allow_html=True)
                
                with col2:
                    confidence = analysis_result.get('confidence', 0)
                    st.metric("Confidence", f"{confidence:.1%}")
                
                with col3:
                    st.metric("Text Length", f"{len(text.split())} words")
                
                # Detailed analysis
                if analysis_depth in ["Detailed", "Comprehensive"]:
                    st.subheader("Detailed Analysis")
                    
                    if 'explanation' in analysis_result:
                        st.write("**Analysis Explanation:**")
                        st.write(analysis_result['explanation'])
                    
                    if 'indicators' in analysis_result:
                        st.write("**Key Sentiment Indicators:**")
                        for indicator in analysis_result['indicators']:
                            st.write(f"‚Ä¢ {indicator}")
                
                # Emotion detection
                if include_emotions and 'emotions' in analysis_result:
                    st.subheader("Emotion Detection")
                    emotions = analysis_result['emotions']
                    
                    for emotion, score in emotions.items():
                        st.progress(score, text=f"{emotion.title()}: {score:.1%}")
                
                # Batch analysis
                if batch_analysis:
                    st.subheader("Sentence-by-Sentence Analysis")
                    sentences = text.split('.')
                    
                    for i, sentence in enumerate(sentences[:10], 1):  # Limit to first 10 sentences
                        if sentence.strip():
                            sentence_sentiment = analyze_sentence_sentiment(sentence.strip())
                            
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                st.write(f"**{i}.** {sentence.strip()}")
                            with col2:
                                sentiment_color = get_sentiment_color(sentence_sentiment)
                                st.markdown(f"<span style='color: {sentiment_color}'>{sentence_sentiment}</span>", 
                                           unsafe_allow_html=True)
                
                # Export results
                if st.button("Export Analysis"):
                    export_data = {
                        "text": text,
                        "analysis_results": analysis_result,
                        "analysis_date": datetime.now().isoformat(),
                        "settings": {
                            "depth": analysis_depth,
                            "emotions": include_emotions,
                            "batch": batch_analysis
                        }
                    }
                    
                    export_json = json.dumps(export_data, indent=2)
                    FileHandler.create_download_link(
                        export_json.encode(), 
                        "sentiment_analysis.json", 
                        "application/json"
                    )
            else:
                st.error(f"Analysis failed: {analysis_result['error']}")

def image_recognition():
    """AI-powered image recognition and analysis"""
    create_tool_header("Image Recognition", "Analyze and recognize objects in images", "üëÅÔ∏è")
    
    uploaded_files = FileHandler.upload_files(['jpg', 'jpeg', 'png', 'gif', 'bmp'], accept_multiple=True)
    
    if uploaded_files:
        # Analysis options
        st.subheader("Recognition Settings")
        
        col1, col2 = st.columns(2)
        with col1:
            analysis_type = st.selectbox("Analysis Type", [
                "General Recognition", "Object Detection", "Scene Analysis", 
                "Text Detection (OCR)", "Face Detection", "Brand Recognition"
            ])
            detail_level = st.selectbox("Detail Level", ["Basic", "Detailed", "Comprehensive"])
        
        with col2:
            include_confidence = st.checkbox("Include Confidence Scores", True)
            include_coordinates = st.checkbox("Include Object Coordinates", False)
        
        for uploaded_file in uploaded_files:
            st.subheader(f"Analyzing: {uploaded_file.name}")
            
            # Display image
            image = FileHandler.process_image_file(uploaded_file)
            if image:
                st.image(image, caption=uploaded_file.name, use_column_width=True)
                
                if st.button(f"Analyze {uploaded_file.name}", key=f"analyze_{uploaded_file.name}"):
                    with st.spinner("Analyzing image with AI..."):
                        # Convert image to bytes for AI analysis
                        img_bytes = io.BytesIO()
                        image.save(img_bytes, format='PNG')
                        img_bytes.seek(0)
                        
                        # Create analysis prompt
                        prompt = create_recognition_prompt(analysis_type, detail_level, include_confidence)
                        
                        # Analyze image
                        analysis_result = ai_client.analyze_image(img_bytes.getvalue(), prompt)
                        
                        if analysis_result:
                            st.subheader("Recognition Results")
                            st.write(analysis_result)
                            
                            # Try to parse structured results
                            try:
                                if analysis_result.strip().startswith('{'):
                                    structured_result = json.loads(analysis_result)
                                    display_structured_recognition(structured_result)
                            except:
                                pass  # Display as plain text if not JSON
                            
                            # Export results
                            if st.button(f"Export Results for {uploaded_file.name}", key=f"export_{uploaded_file.name}"):
                                export_data = {
                                    "image_name": uploaded_file.name,
                                    "analysis_type": analysis_type,
                                    "detail_level": detail_level,
                                    "results": analysis_result,
                                    "analysis_date": datetime.now().isoformat()
                                }
                                
                                export_json = json.dumps(export_data, indent=2)
                                FileHandler.create_download_link(
                                    export_json.encode(), 
                                    f"recognition_results_{uploaded_file.name}.json", 
                                    "application/json"
                                )
                
                st.markdown("---")

def text_translator():
    """AI-powered text translation"""
    create_tool_header("Text Translator", "Translate text between languages", "üåç")
    
    # Input methods
    input_method = st.radio("Input Method", ["Text Input", "File Upload"])
    
    if input_method == "Text Input":
        source_text = st.text_area("Enter text to translate:", height=200)
    else:
        uploaded_file = FileHandler.upload_files(['txt'], accept_multiple=False)
        if uploaded_file:
            source_text = FileHandler.process_text_file(uploaded_file[0])
            st.text_area("Uploaded text:", source_text, height=150, disabled=True)
        else:
            source_text = ""
    
    # Translation settings
    st.subheader("Translation Settings")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        source_language = st.selectbox("Source Language", [
            "Auto-Detect", "English", "Spanish", "French", "German", "Italian", 
            "Portuguese", "Russian", "Chinese", "Japanese", "Korean", "Arabic", "Hindi"
        ])
    
    with col2:
        target_language = st.selectbox("Target Language", [
            "Spanish", "French", "German", "Italian", "Portuguese", "Russian",
            "Chinese", "Japanese", "Korean", "Arabic", "Hindi", "English"
        ])
    
    with col3:
        translation_style = st.selectbox("Translation Style", [
            "Standard", "Formal", "Casual", "Technical", "Literary"
        ])
    
    # Advanced options
    with st.expander("Advanced Options"):
        preserve_formatting = st.checkbox("Preserve Formatting", True)
        include_alternatives = st.checkbox("Include Alternative Translations", False)
        cultural_adaptation = st.checkbox("Cultural Adaptation", False)
    
    if st.button("Translate Text") and source_text and target_language:
        with st.spinner(f"Translating to {target_language}..."):
            # Enhanced translation prompt
            translation_prompt = create_translation_prompt(
                source_text, target_language, translation_style, 
                preserve_formatting, cultural_adaptation
            )
            
            translated_text = ai_client.generate_text(translation_prompt)
            
            if translated_text:
                st.subheader("Translation Results")
                
                # Display original and translated text side by side
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Original Text:**")
                    st.text_area("", source_text, height=200, disabled=True, key="original")
                
                with col2:
                    st.markdown(f"**Translated Text ({target_language}):**")
                    st.text_area("", translated_text, height=200, disabled=True, key="translated")
                
                # Translation quality metrics
                st.subheader("Translation Quality")
                quality_metrics = assess_translation_quality(source_text, translated_text)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Estimated Quality", quality_metrics['quality_score'])
                with col2:
                    st.metric("Fluency", quality_metrics['fluency'])
                with col3:
                    st.metric("Completeness", quality_metrics['completeness'])
                
                # Alternative translations
                if include_alternatives:
                    st.subheader("Alternative Translations")
                    alternatives = generate_translation_alternatives(source_text, target_language)
                    
                    for i, alt in enumerate(alternatives, 1):
                        st.write(f"**Alternative {i}:** {alt}")
                
                # Export translation
                FileHandler.create_download_link(
                    translated_text.encode(), 
                    f"translation_{target_language.lower()}.txt", 
                    "text/plain"
                )

# Helper Functions

def send_to_all_models(message, models):
    """Send message to all selected models"""
    responses = {}
    
    for model in models:
        try:
            response = ai_client.generate_text(message, model=model)
            responses[model] = response
        except Exception as e:
            responses[model] = f"Error: {str(e)}"
    
    # Add to chat history
    st.session_state.chat_history.append({
        'user_message': message,
        'responses': responses,
        'timestamp': datetime.now().isoformat()
    })
    
    st.rerun()

def export_chat_history():
    """Export chat history to file"""
    if st.session_state.chat_history:
        chat_data = {
            'chat_history': st.session_state.chat_history,
            'exported_at': datetime.now().isoformat()
        }
        
        chat_json = json.dumps(chat_data, indent=2)
        FileHandler.create_download_link(
            chat_json.encode(), 
            f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 
            "application/json"
        )

def generate_content(content_type, topic, audience, tone, length, language, creativity, instructions, **kwargs):
    """Generate content using AI"""
    prompt = f"""
    Create a {content_type.lower()} about "{topic}" with the following specifications:
    
    - Target Audience: {audience}
    - Tone: {tone}
    - Length: {length}
    - Language: {language}
    - Creativity Level: {creativity}
    
    Additional Instructions: {instructions if instructions else 'None'}
    
    """
    
    # Add content-specific instructions
    if content_type == "Blog Post":
        prompt += "\nInclude an engaging introduction, well-structured body with subheadings, and a compelling conclusion."
        if kwargs.get('include_outline'):
            prompt += "\nStart with an outline before the content."
        if kwargs.get('include_seo'):
            prompt += "\nOptimize for SEO with relevant keywords."
    
    elif content_type == "Social Media Post":
        platform = kwargs.get('platform', 'general')
        prompt += f"\nOptimize for {platform}. Keep it engaging and shareable."
        if kwargs.get('include_hashtags'):
            prompt += "\nInclude relevant hashtags."
    
    return ai_client.generate_text(prompt, max_tokens=2000)

def analyze_content(content):
    """Analyze generated content"""
    words = content.split()
    word_count = len(words)
    reading_time = max(1, word_count // 200)  # Assume 200 WPM reading speed
    
    # Simple readability assessment
    sentences = content.split('.')
    avg_sentence_length = word_count / len(sentences) if sentences else 0
    
    if avg_sentence_length < 15:
        readability = "Easy"
    elif avg_sentence_length < 25:
        readability = "Medium"
    else:
        readability = "Complex"
    
    return {
        'word_count': word_count,
        'reading_time': reading_time,
        'readability_level': readability
    }

def enhance_image_prompt(prompt, style, mood, color_scheme):
    """Enhance image generation prompt"""
    enhanced = prompt
    
    if style != "Natural":
        enhanced += f", {style.lower()} style"
    
    if mood != "Neutral":
        enhanced += f", {mood.lower()} mood"
    
    if color_scheme != "Natural":
        enhanced += f", {color_scheme.lower()}"
    
    enhanced += ", high quality, detailed, professional"
    
    return enhanced

def get_sentiment_color(sentiment):
    """Get color for sentiment display"""
    colors = {
        'positive': 'green',
        'negative': 'red',
        'neutral': 'gray',
        'mixed': 'orange'
    }
    return colors.get(sentiment.lower(), 'black')

def analyze_sentence_sentiment(sentence):
    """Analyze sentiment of individual sentence"""
    # Simple keyword-based sentiment for demo
    positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'love', 'like']
    negative_words = ['bad', 'terrible', 'awful', 'hate', 'dislike', 'horrible', 'worst']
    
    sentence_lower = sentence.lower()
    
    positive_count = sum(1 for word in positive_words if word in sentence_lower)
    negative_count = sum(1 for word in negative_words if word in sentence_lower)
    
    if positive_count > negative_count:
        return 'positive'
    elif negative_count > positive_count:
        return 'negative'
    else:
        return 'neutral'

def create_recognition_prompt(analysis_type, detail_level, include_confidence):
    """Create prompt for image recognition"""
    base_prompt = f"Analyze this image and provide {detail_level.lower()} {analysis_type.lower()}."
    
    if analysis_type == "Object Detection":
        base_prompt += " Identify and describe all objects visible in the image."
    elif analysis_type == "Scene Analysis":
        base_prompt += " Describe the scene, setting, and overall context."
    elif analysis_type == "Text Detection (OCR)":
        base_prompt += " Extract and transcribe any text visible in the image."
    elif analysis_type == "Face Detection":
        base_prompt += " Identify faces and describe their characteristics."
    
    if include_confidence:
        base_prompt += " Include confidence levels for your identifications."
    
    if detail_level == "Comprehensive":
        base_prompt += " Provide comprehensive analysis with technical details."
    
    return base_prompt

def display_structured_recognition(result):
    """Display structured recognition results"""
    if isinstance(result, dict):
        for key, value in result.items():
            st.write(f"**{key.title()}**: {value}")

def create_translation_prompt(text, target_language, style, preserve_formatting, cultural_adaptation):
    """Create enhanced translation prompt"""
    prompt = f"Translate the following text to {target_language}"
    
    if style != "Standard":
        prompt += f" using a {style.lower()} style"
    
    if preserve_formatting:
        prompt += ", preserving the original formatting and structure"
    
    if cultural_adaptation:
        prompt += ", adapting cultural references and idioms appropriately"
    
    prompt += f":\n\n{text}"
    
    return prompt

def assess_translation_quality(original, translated):
    """Assess translation quality (simplified)"""
    # Simple quality metrics based on length ratio and structure
    length_ratio = len(translated) / len(original) if original else 0
    
    quality_score = "Good" if 0.7 <= length_ratio <= 1.5 else "Fair"
    fluency = "High" if length_ratio > 0.5 else "Medium"
    completeness = "Complete" if length_ratio > 0.8 else "Partial"
    
    return {
        'quality_score': quality_score,
        'fluency': fluency,
        'completeness': completeness
    }

def generate_translation_alternatives(text, target_language):
    """Generate alternative translations"""
    # This would generate multiple translation variants
    alternatives = [
        f"Alternative translation 1 for: {text[:50]}...",
        f"Alternative translation 2 for: {text[:50]}...",
        f"Alternative translation 3 for: {text[:50]}..."
    ]
    return alternatives[:2]  # Limit to 2 alternatives

# Placeholder functions for remaining tools
def text_summarizer():
    """AI text summarization tool"""
    st.info("Text Summarizer - Coming soon!")

def model_comparison():
    """AI model comparison tool"""
    st.info("Model Comparison - Coming soon!")

def prompt_optimizer():
    """AI prompt optimization tool"""
    st.info("Prompt Optimizer - Coming soon!")

def data_insights():
    """AI data insights tool"""
    st.info("Data Insights - Coming soon!")

def conversational_ai():
    """Advanced conversational AI chatbot"""
    create_tool_header("Conversational AI", "Have natural conversations with AI", "ü§ñüí¨")
    
    # Check API key availability
    import os
    gemini_available = bool(os.getenv("GOOGLE_API_KEY"))
    
    if not gemini_available:
        st.error("üîë No Google API key found! Please add GOOGLE_API_KEY to your environment variables to use this feature.")
        st.info("üí° You can get a Google API key from:")
        st.markdown("- **Gemini**: https://makersuite.google.com/app/apikey")
        return
    
    # Chatbot configuration
    st.subheader("üîß Configure Your AI Assistant")
    
    col1, col2 = st.columns(2)
    with col1:
        model_choice = "gemini"  # Only Gemini is available
        st.info("ü§ñ Using Google Gemini AI model")
        personality = st.selectbox(
            "Personality", 
            ["Helpful Assistant", "Creative Writer", "Technical Expert", "Casual Friend", "Professional Mentor"],
            help="Choose the AI's conversation style"
        )
        
    with col2:
        conversation_mode = st.selectbox(
            "Conversation Mode",
            ["General Chat", "Question & Answer", "Brainstorming", "Problem Solving", "Learning Assistant"],
            help="Set the conversation context"
        )
        max_tokens = st.slider("Response Length", 100, 2000, 500, 50, help="Maximum tokens per response")
    
    # Custom system prompt
    with st.expander("üéØ Custom Instructions (Optional)"):
        custom_instructions = st.text_area(
            "Additional instructions for the AI",
            placeholder="e.g., 'Always respond in a friendly tone' or 'Focus on practical solutions'",
            height=100
        )
    
    # Initialize conversation history
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
        
    # Build system prompt based on settings
    system_prompts = {
        "Helpful Assistant": "You are a helpful, knowledgeable assistant. Provide clear, accurate, and useful responses.",
        "Creative Writer": "You are a creative writing assistant. Help with storytelling, poetry, and creative expression.",
        "Technical Expert": "You are a technical expert. Provide detailed, accurate technical information and solutions.",
        "Casual Friend": "You are a friendly, casual conversational partner. Keep responses warm and engaging.",
        "Professional Mentor": "You are a professional mentor. Provide guidance, advice, and constructive feedback."
    }
    
    base_prompt = system_prompts[personality]
    if custom_instructions:
        base_prompt += f"\n\nAdditional instructions: {custom_instructions}"
        
    if conversation_mode != "General Chat":
        base_prompt += f"\n\nContext: This conversation is focused on {conversation_mode.lower()}."
    
    # Chat interface
    st.markdown("---")
    st.subheader("üí¨ Conversation")
    
    # Display conversation history
    if st.session_state.conversation_history:
        chat_container = st.container()
        with chat_container:
            for i, exchange in enumerate(st.session_state.conversation_history):
                # User message
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, rgba(100, 150, 255, 0.1), rgba(150, 100, 255, 0.1)); 
                            padding: 1rem; border-radius: 10px; margin: 0.5rem 0; border-left: 4px solid #6496ff;">
                    <strong>üë§ You:</strong><br>
                    {exchange['user']}
                </div>
                """, unsafe_allow_html=True)
                
                # AI response
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, rgba(150, 255, 150, 0.1), rgba(255, 150, 150, 0.1)); 
                            padding: 1rem; border-radius: 10px; margin: 0.5rem 0; border-left: 4px solid #64ff96;">
                    <strong>ü§ñ AI ({model_choice.title() if model_choice else 'Unknown'}):</strong><br>
                    {exchange['ai']}
                </div>
                """, unsafe_allow_html=True)
    
    # User input
    st.markdown("---")
    user_input = st.text_area(
        "üí≠ Your message:",
        height=120,
        placeholder=f"Ask me anything! I'm configured as a {personality.lower()} for {conversation_mode.lower()}..."
    )
    
    # Control buttons
    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
    with col1:
        if st.button("üì§ Send Message", type="primary"):
            if user_input.strip():
                send_conversational_message(user_input, model_choice, base_prompt, max_tokens)
    
    with col2:
        if st.button("üóëÔ∏è Clear Chat"):
            st.session_state.conversation_history = []
            st.rerun()
    
    with col3:
        if st.button("üíæ Export Chat"):
            export_conversation_history()
            
    with col4:
        if st.session_state.conversation_history:
            if st.button("üîÑ Continue"):
                st.text_area(
                    "Continue the conversation:",
                    value="That's interesting. Can you tell me more about...",
                    key="continue_prompt"
                )
    
    # Quick suggestions
    if not st.session_state.conversation_history:
        st.subheader("üí° Quick Start Ideas")
        suggestions = {
            "General Chat": ["Tell me a joke", "What's your favorite book?", "How are you today?"],
            "Question & Answer": ["Explain quantum physics", "How does photosynthesis work?", "What is artificial intelligence?"],
            "Brainstorming": ["Ideas for a birthday party", "Creative project concepts", "Business name suggestions"],
            "Problem Solving": ["Help me organize my schedule", "Solve this math problem", "Debug my code logic"],
            "Learning Assistant": ["Teach me Spanish basics", "Explain machine learning", "Help me understand history"]
        }
        
        cols = st.columns(3)
        for i, suggestion in enumerate(suggestions.get(conversation_mode, suggestions["General Chat"])):
            with cols[i % 3]:
                if st.button(f"üí¨ {suggestion}", key=f"suggestion_{i}"):
                    st.session_state.temp_input = suggestion
                    send_conversational_message(suggestion, model_choice, base_prompt, max_tokens)
    
    # Conversation stats
    if st.session_state.conversation_history:
        st.markdown("---")
        st.subheader("üìä Conversation Stats")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Messages Exchanged", len(st.session_state.conversation_history) * 2)
        with col2:
            total_words = sum(len(ex['user'].split()) + len(ex['ai'].split()) 
                            for ex in st.session_state.conversation_history)
            st.metric("Total Words", total_words)
        with col3:
            st.metric("AI Model", model_choice.title() if model_choice else 'Unknown')

def send_conversational_message(message, model, system_prompt, max_tokens):
    """Send a message in conversational context"""
    with st.spinner(f"ü§ñ AI is thinking..."):
        # Build conversation context
        context = f"System: {system_prompt}\n\n"
        
        # Add recent conversation history for context (last 5 exchanges)
        recent_history = st.session_state.conversation_history[-5:] if st.session_state.conversation_history else []
        for exchange in recent_history:
            context += f"User: {exchange['user']}\nAssistant: {exchange['ai']}\n\n"
            
        context += f"User: {message}\nAssistant: "
        
        # Generate response
        response = ai_client.generate_text(context, model=model, max_tokens=max_tokens)
        
        # Check for error responses
        if response.startswith("Error") or response.startswith("Gemini model not available"):
            st.error(f"‚ùå {response}")
            if "GOOGLE_API_KEY" in response or "API key" in response.lower():
                st.info("üí° Please check your GOOGLE_API_KEY configuration in the environment variables.")
            return
        
        # Add to conversation history
        st.session_state.conversation_history.append({
            'user': message,
            'ai': response,
            'timestamp': datetime.now().isoformat(),
            'model': model
        })
        
        st.rerun()

def export_conversation_history():
    """Export conversation history to file"""
    if st.session_state.conversation_history:
        conversation_data = {
            'conversation': st.session_state.conversation_history,
            'exported_at': datetime.now().isoformat(),
            'total_exchanges': len(st.session_state.conversation_history)
        }
        
        conversation_json = json.dumps(conversation_data, indent=2)
        FileHandler.create_download_link(
            conversation_json.encode(), 
            f"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 
            "application/json"
        )
        st.success("üì• Conversation exported! Check your downloads.")

def ocr_reader():
    """OCR text extraction tool"""
    st.info("OCR Reader - Coming soon!")

def voice_synthesis():
    """Voice synthesis tool"""
    st.info("Voice Synthesis - Coming soon!")

def pattern_recognition():
    """Pattern recognition tool"""
    st.info("Pattern Recognition - Coming soon!")

def story_writer():
    """AI story writing tool"""
    st.info("Story Writer - Coming soon!")

def refine_content(content):
    """Refine generated content"""
    st.info("Content refinement feature - Coming soon!")
